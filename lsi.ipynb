{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 18846\n",
      "Topic 1: com, use, like, peopl, know, articl, think, god, univers, say\n",
      "Topic 2: god, christian, jesus, peopl, believ, say, religion, faith, christ, sin\n",
      "Topic 3: god, window, christian, jesus, file, scsi, dos, drive, card, use\n",
      "Topic 4: key, clipper, chip, encrypt, com, govern, escrow, netcom, secur, law\n",
      "Topic 5: armenian, israel, isra, turkish, arab, muslim, jew, state, armenia, serdar\n",
      "Topic 6: key, game, chip, encrypt, clipper, team, escrow, god, use, secur\n",
      "Topic 7: scsi, drive, ide, chip, hard, disk, ohio, card, bus, key\n",
      "Topic 8: nasa, ohio, space, gov, cleveland, state, magnus, cwru, digex, acs\n",
      "Topic 9: ohio, cleveland, israel, state, cwru, magnus, freenet, acs, isra, window\n",
      "Topic 10: armenian, turkish, god, com, serdar, key, argic, armenia, ohio, muslim\n",
      "Topic 11: sgi, uk, moral, livesey, scsi, israel, keith, caltech, wpd, solntze\n",
      "Topic 12: uk, ac, car, cramer, optilink, homosexu, gay, clayton, bike, pitt\n",
      "Topic 13: keith, sgi, livesey, moral, caltech, armenian, solntze, wpd, jon, ohio\n",
      "Topic 14: cramer, optilink, homosexu, ohio, gay, clayton, magnus, acs, state, men\n",
      "Topic 15: pitt, cs, geb, gordon, banks, access, cramer, pittsburgh, homosexu, optilink\n",
      "Topic 16: uk, stratus, ac, sw, cdt, scsi, cleveland, fbi, rocket, batf\n",
      "Topic 17: sandvik, kent, apple, uk, newton, ac, cleveland, car, freenet, alink\n",
      "Topic 18: sandvik, state, ohio, magnus, kent, acs, apple, newton, nasa, stratus\n",
      "Topic 19: access, digex, pat, uk, net, ac, express, onlin, prb, univers\n",
      "Topic 20: ohio, uk, magnus, acs, scsi, state, window, drive, ac, com\n",
      "Topic 21: ca, columbia, cc, drive, window, car, scsi, cunixb, gld, file\n",
      "Topic 22: andrew, cmu, drive, mellon, carnegi, pittsburgh, pa, game, scsi, file\n",
      "Topic 23: stratus, uiuc, cso, sw, car, cdt, urbana, illinoi, uxa, cmu\n",
      "Topic 24: uiuc, cc, cso, columbia, gld, cunixb, game, illinoi, urbana, nasa\n",
      "Topic 25: cc, columbia, andrew, cmu, gld, toronto, cunixb, henri, card, stratus\n",
      "Topic 26: uiuc, cso, andrew, cmu, nasa, gov, ca, card, illinoi, urbana\n",
      "Topic 27: netcom, toronto, henri, zoo, spencer, henry, zoolog, ai, georgia, david\n",
      "Topic 28: georgia, ai, window, uga, card, michael, toronto, covington, mcovingt, gatech\n",
      "Topic 29: ai, georgia, uga, covington, mcovingt, michael, stratus, problem, aisun3, nasa\n",
      "Topic 30: netcom, window, ca, dos, 408, uk, god, 9760, 241, servic\n",
      "Topic 31: ibm, gun, car, austin, uiuc, georgia, ai, cso, islam, cmu\n",
      "Topic 32: uiuc, sun, 00, cso, ca, christian, columbia, illinoi, church, moral\n",
      "Topic 33: god, gun, file, imag, game, uiuc, cso, format, virginia, car\n",
      "Topic 34: ___, __, car, islam, hp, _____, fbi, sgi, ca, imag\n",
      "Topic 35: ___, __, sun, gun, islam, game, muslim, _____, colorado, drive\n",
      "Topic 36: islam, sgi, muslim, drive, livesey, jaeger, nasa, wpd, jon, bu\n",
      "Topic 37: scsi, car, sun, netcom, driver, washington, ide, bus, card, window\n",
      "Topic 38: cs, hp, columbia, nyx, team, monitor, imag, color, cmu, bit\n",
      "Topic 39: hp, god, moral, atheist, govern, exist, sale, isc, com, object\n",
      "Topic 40: mit, buffalo, ibm, washington, scsi, gun, 00, berkeley, god, host\n",
      "Topic 41: hp, christian, jesus, church, mit, gun, colorado, toronto, buffalo, problem\n",
      "Topic 42: sun, car, ibm, monitor, mac, christian, appl, __, jesus, austin\n",
      "Topic 43: virginia, scsi, sgi, hp, mit, toronto, game, livesey, columbia, gun\n",
      "Topic 44: drive, moral, file, christian, 00, toronto, gov, nasa, virginia, david\n",
      "Topic 45: game, ca, espn, 00, netcom, car, scsi, christian, buffalo, ibm\n",
      "Topic 46: virginia, space, buffalo, alaska, univers, sun, team, dseg, ti, nsmca\n",
      "Topic 47: buffalo, ti, org, dseg, cs, sgi, com, jake, mit, cc\n",
      "Topic 48: msg, 00, food, key, dos, toronto, gov, team, god, berkeley\n",
      "Topic 49: virginia, sun, au, gatech, key, islam, mail, prism, buffalo, mit\n",
      "Topic 50: buffalo, msg, nyx, ubvmsb, acsu, govern, vm, software, vnew, food\n",
      "Topic 51: gatech, hp, buffalo, scsi, prism, mac, modem, cc, printer, bike\n",
      "Topic 52: virginia, gatech, caltech, prism, game, muslim, cs, com, msg, imag\n",
      "Topic 53: dresden, gatech, tu, prism, inf, beck, msg, convex, drive, sale\n",
      "Topic 54: washington, modem, au, convex, dresden, tu, jake, clock, port, inf\n",
      "Topic 55: tu, dresden, inf, beck, key, jake, andre_beck, irzr17, keith, irs\n",
      "Topic 56: tu, dresden, modem, inf, file, washington, beck, mac, clinton, msg\n",
      "Topic 57: window, monitor, jake, org, scsi, new, hockey, space, austin, christian\n",
      "Topic 58: jake, key, bony1, bony, berkeley, livni, mit, msg, space, udel\n",
      "Topic 59: ti, dseg, jake, 00, pyron, mccall, colorado, wpi, skndiv, umd\n",
      "Topic 60: david, indiana, modem, sternlight, islam, mail, printer, sale, ucs, window\n",
      "Topic 61: david, jake, au, stanford, bony, bony1, game, indiana, sternlight, livni\n",
      "Topic 62: umd, modem, mit, eng, convex, port, 00, wam, font, muslim\n",
      "Topic 63: indiana, umd, ti, dseg, ucs, org, eng, version, mac, berkeley\n",
      "Topic 64: washington, bike, ti, dseg, mit, team, christian, atheist, wpi, david\n",
      "Topic 65: au, printer, font, berkeley, org, law, msg, convex, driver, alaska\n",
      "Topic 66: umd, eng, org, nyx, unix, christian, david, wam, virginia, udel\n",
      "Topic 67: intercon, amanda, indiana, monitor, ucs, walker, modem, scsi, au, clipper\n",
      "Topic 68: intercon, jesus, amanda, msg, moral, brian, chip, john, newsreader, mit\n",
      "Topic 69: alaska, wpi, indiana, monitor, 00, michael, berkeley, nsmca, aurora, acad3\n",
      "Topic 70: colorado, org, spot, boulder, intercon, berkeley, au, roger, rider, amanda\n",
      "Topic 71: imag, duke, bit, color, washington, ysu, mike, john, yfn, org\n",
      "Topic 72: au, colorado, berkeley, nec, behanna, moral, udel, program, modem, australia\n",
      "Topic 73: colorado, convex, monitor, book, law, uci, dos, islam, file, org\n",
      "Topic 74: isc, au, 00, key, jesus, br, rit, brian, wpi, book\n",
      "Topic 75: 00, colorado, dos, washington, nec, monitor, use, stanford, mil, behanna\n",
      "Topic 76: berkeley, umd, tek, right, ac, speed, hamburg, bontchev, eng, informatik\n",
      "Topic 77: alaska, org, uci, cd, sin, udel, use, uni, informatik, nsmca\n",
      "Topic 78: au, alaska, upenn, nyx, sas, dartmouth, john, du, colorado, aurora\n",
      "Topic 79: dos, duke, uci, au, mail, bit, umd, msg, mil, sale\n",
      "Topic 80: uci, nec, ysu, book, yfn, behanna, hp, oac, orion, font\n",
      "Topic 81: mil, navy, book, udel, colorado, nec, duke, oasys, behanna, dt\n",
      "Topic 82: duke, berkeley, hamburg, informatik, christian, power, bontchev, uni, file, monitor\n",
      "Topic 83: wpi, stanford, john, ysu, utexas, yfn, harvard, alaska, file, portal\n",
      "Topic 84: washington, indiana, font, optilink, cramer, hamburg, new, jewish, informatik, uni\n",
      "Topic 85: wpi, umd, berkeley, duke, microsoft, know, tek, dos, church, hp\n",
      "Topic 86: mil, convex, wpi, hamburg, key, bontchev, navy, informatik, uni, intercon\n",
      "Topic 87: wpi, driver, mous, cd, duke, mac, player, ac, sound, jim\n",
      "Topic 88: mark, intercon, msg, amanda, problem, mous, church, caltech, convex, key\n",
      "Topic 89: berkeley, mous, org, driver, jesus, nec, behanna, win, insur, cs\n",
      "Topic 90: mous, imag, chip, font, world, printer, dartmouth, homosexu, udel, dos\n",
      "Topic 91: jim, usc, imag, pat, halat, att, post, sin, church, comput\n",
      "Topic 92: wpi, font, monitor, list, okcforum, mail, cwru, church, printer, mathew\n",
      "Topic 93: berkeley, imag, mike, phone, org, number, mit, nyx, line, nec\n",
      "Topic 94: chip, program, ysu, window, yfn, mac, jesus, isc, rit, law\n",
      "Topic 95: stanford, imag, dos, udel, insur, mac, number, mot, pc, alaska\n",
      "Topic 96: mous, microsoft, indiana, berkeley, file, law, post, washington, book, group\n",
      "Topic 97: dartmouth, brian, michael, usc, radar, mous, fan, berkeley, detector, driver\n",
      "Topic 98: player, printer, font, data, hockey, play, nhl, like, cd, fi\n",
      "Topic 99: mark, phone, ecn, uoknor, callison, think, udel, key, upenn, petch\n",
      "Topic 100: uchicago, batteri, att, maynard, laurentian, roger, chip, midway, dartmouth, chicago\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Step 1: Data Collection\n",
    "newsgroups_data = fetch_20newsgroups(subset='all')\n",
    "documents = newsgroups_data.data\n",
    "\n",
    "\n",
    "# Step 2: Text Preprocessing\n",
    "# Tokenization, lowercase conversion, stop word removal, and stemming\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = text.split()\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    tokens = [stemmer.stem(token) for token in tokens if token not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Step 3: Create Term-Document Matrix\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(preprocessed_documents)\n",
    "\n",
    "# Step 4: SVD Decomposition\n",
    "num_topics = 100  # Number of topics to reduce the matrix to\n",
    "svd = TruncatedSVD(n_components=num_topics)\n",
    "lsa_matrix = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "# Step 5: Topic Exploration\n",
    "# Singular vectors and their corresponding terms\n",
    "singular_vectors = svd.components_\n",
    "\n",
    "# Print the top terms for each topic\n",
    "for topic_idx, topic in enumerate(singular_vectors):\n",
    "    top_terms_idx = topic.argsort()[::-1][:10]  # Get the indices of top terms\n",
    "    top_terms = [vectorizer.get_feature_names_out()[idx] for idx in top_terms_idx]\n",
    "    top_terms_str = [str(term) for term in top_terms]  # Convert numpy arrays to strings\n",
    "    print(f\"Topic {topic_idx + 1}: {', '.join(top_terms_str)}\")\n",
    "\n",
    "# Additional analysis or visualization can be performed based on the topics extracted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Relevant Documents:\n",
      "1. Document 12949: From: u95_dgold@vaxc.stevens-tech.edu\n",
      "Subject: EMI filter, What's in it?\n",
      "Lines: 8\n",
      "Organization: Stevens Institute Of Technology\n",
      "\n",
      "Could someone tell me what's in a Cornell-Dubilier EMI Filter\n",
      "FIL 3363-001?\n",
      "\n",
      "It is rated at 13A 115/250VAC 50/60HZ.  Is it just MOV's and ferrite?\n",
      "\n",
      "Dave  /  n2mxx\n",
      "Stevens Institute of Technology\n",
      "Hoboken, New Jersey\n",
      "\n",
      "2. Document 13717: From: grahamt@phantom.gatech.edu (Graham E. Thomas)\n",
      "Subject: Re: BLAST to the past!\n",
      "Organization: Georgia Institute of Technology\n",
      "Lines: 17\n",
      "NNTP-Posting-Host: oit.gatech.edu\n",
      "\n",
      "amh2@ns1.cc.lehigh.edu (ALOIS M. HIMSL) writes:\n",
      ">be worthwhile?  Or how about something like the old MGB with new technology?\n",
      ">Just think about it - the old style with upgraded safety features and perhaps a\n",
      ">natural gas operated engine for less than 10K. I think it would go over well.\n",
      ">What is your opinion??????\n",
      ">Al H\n",
      "\n",
      "Well, the MGB is currently in production for the English market, built\n",
      "by Rover. It now has a V8, improved suspention, and a slightly\n",
      "updated body. Too bad it's only available in GB and would set one\n",
      "of us back about $42,000+.\n",
      "\n",
      " \n",
      "-- \n",
      "Graham E. Thomas                  *  blah blah blah blah blah  \n",
      "Georgia Institute of Technology   *  blah blah blah blah blah     \n",
      "Internet: grahamt@oit.gatech.edu  *  blah blah blah blah blah  \n",
      "\n",
      "3. Document 8332: From: gt4661a@prism.gatech.EDU (gt4661a gt4661a PAOLO,MARC ANTHONY)\n",
      "Subject: Computer For Sale\n",
      "Distribution: atl\n",
      "Organization: Georgia Institute of Technology\n",
      "Lines: 5\n",
      "\n",
      "-- \n",
      "PAOLO,MARC ANTHONY\n",
      "Georgia Institute of Technology, Atlanta Georgia, 30332\n",
      "uucp:     ...!{allegra,amd,hplabs,ut-ngp}!gatech!prism!gt4661a\n",
      "Internet: gt4661a@prism.gatech.edu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Load Query from a Text Document\n",
    "with open(\"query.txt\", \"r\") as query_file:\n",
    "    query_text = query_file.read()\n",
    "\n",
    "# Preprocess the query in the same way as the dataset\n",
    "preprocessed_query = preprocess_text(query_text)\n",
    "\n",
    "# Step 7: Project the Query into LSI Space\n",
    "query_vector = vectorizer.transform([preprocessed_query])  # Transform the query into TF-IDF space\n",
    "query_lsi = svd.transform(query_vector)  # Project the query into the LSI space\n",
    "\n",
    "# Step 8: Compute Cosine Similarity\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute the cosine similarity between the query and LSI-transformed documents\n",
    "similarities = cosine_similarity(query_lsi, lsa_matrix)\n",
    "\n",
    "# Find the most relevant documents\n",
    "top_n = 3  # You can change this to the number of top relevant documents you want\n",
    "top_document_indices = similarities.argsort()[0][::-1][:top_n]\n",
    "\n",
    "# Print the most relevant documents\n",
    "print(\"Top Relevant Documents:\")\n",
    "for i, doc_idx in enumerate(top_document_indices):\n",
    "    print(f\"{i + 1}. Document {doc_idx + 1}: {documents[doc_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Categories (Topics): ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Ground truth labels are stored in newsgroups_data.target\n",
    "ground_truth_labels = newsgroups_data.target\n",
    "\n",
    "# If you want to see the unique categories (topics) in the dataset, you can use:\n",
    "unique_categories = list(newsgroups_data.target_names)\n",
    "print(\"Unique Categories (Topics):\", unique_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Het Pandya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 20  # You can adjust the number of clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "cluster_labels = kmeans.fit_predict(lsa_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[282   0   0   2   1 158   0   0   0   0   0 132   0 169  38   0  16   1\n",
      "    0   0]\n",
      " [628   1   0   1   0   3   0   2   0   2 330   0   3   1   0   0   2   0\n",
      "    0   0]\n",
      " [273   9   0   0   0   3   0   2   0  13 678   0   2   0   0   0   5   0\n",
      "    0   0]\n",
      " [385   2   0   0   1   0   3   3   0   5 575   0   2   0   0   0   6   0\n",
      "    0   0]\n",
      " [559   1   0   0   0   1   0  13   0   1 368   0   2   0   0   0  18   0\n",
      "    0   0]\n",
      " [532   2   0   0   6   0   0   2   0   1 422   0   2   0   0   0  21   0\n",
      "    0   0]\n",
      " [707  13   0   5   0   3  17  33   0   7 167   0   8   0   0   0  15   0\n",
      "    0   0]\n",
      " [893   2   0   3   0  37   0  30   0   1   5   0   0   0   0   0  19   0\n",
      "    0   0]\n",
      " [954   0   0   0   0  14   0   6   0   1   1   0   9   0   0   0  11   0\n",
      "    0   0]\n",
      " [484  15   1   4   0   4 469   7   0   1   0   0   1   0   0   0   8   0\n",
      "    0   0]\n",
      " [182  25   0   0   0   4 702   6   0   0   1   0  28   0   0   0  51   0\n",
      "    0   0]\n",
      " [321   0   0  16 503  69   0   8   0  34  30   0   0   0   0   0   9   1\n",
      "    0   0]\n",
      " [856   3  12   0   2   2   2   6   0   1  89   1   2   0   0   0   8   0\n",
      "    0   0]\n",
      " [791   0   0   2   0  36   0   5   0   4   4   0   1   3   0  77   9   0\n",
      "   58   0]\n",
      " [738   4  81   1   0  33   0   0   0 112  10   0   0   0   0   0   8   0\n",
      "    0   0]\n",
      " [348   6   0   0   0  32   0   1   0   0   1   0   0 595   1   0  12   1\n",
      "    0   0]\n",
      " [181  15   0  69   4 628   0   5   0   1   1   0   2   0   0   0   4   0\n",
      "    0   0]\n",
      " [217   3   0   0   0 129   0   1 172   0   0   0  16   3   0   0   2   0\n",
      "    0 397]\n",
      " [270   0   0   5   1 321   2  26   0   1   0   0  17   3   0   0   0 129\n",
      "    0   0]\n",
      " [271   0   0   0   0 104   0   2   0   4   0  15   0 153  70   2   6   1\n",
      "    0   0]]\n",
      "purity: 0.29152074710813963\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix between ground truth labels and cluster labels\n",
    "confusion = confusion_matrix(ground_truth_labels, cluster_labels)\n",
    "print(confusion)\n",
    "\n",
    "# Calculate purity\n",
    "purity = np.sum(np.max(confusion, axis=0)) / np.sum(confusion)\n",
    "print(f\"purity: {purity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI score: 0.3581136714869967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "\n",
    "nmi = normalized_mutual_info_score(ground_truth_labels, cluster_labels)\n",
    "print(f\"NMI score: {nmi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.0878960135399179\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouette_avg = silhouette_score(lsa_matrix, cluster_labels)\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
